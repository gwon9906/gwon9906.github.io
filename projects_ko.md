---
layout: page
title: 프로젝트
permalink: /projects_ko/
---

<div style="text-align: right; margin-bottom: 20px;">
  <a href="/projects" style="text-decoration: none; padding: 8px 16px; background-color: #0366d6; color: white; border-radius: 5px;">🇺🇸 English</a>
</div>

# 연구 및 개발 프로젝트

---

## 🌟 <a name="ultra-low-snr"></a>Ultra Low SNR 신호 복원 및 분류

**역할**: 학부 연구생  
**기간**: 2025년 3월 - 현재  
**상태**: 진행 중

### 프로젝트 개요
극한의 낮은 신호 대 잡음비(Ultra Low SNR) 환경에서 신호 복원 및 분류를 위한 딥러닝 모델 연구. 연쇄 모델(Cascaded Model)과 Multi-Task Learning(MTL) 아키텍처의 비교 분석을 통해 열화된 신호 처리를 위한 최적의 접근 방식을 규명하고자 합니다.

### 문제 정의
극한 SNR 환경(SNR: -30dB ~ -10dB)에서는 전통적인 신호 처리 방법으로 효과적인 신호 복원 및 분류가 불가능합니다. 본 연구는 딥러닝을 활용하여 이러한 한계를 극복하고 극한 노이즈 환경에서도 신뢰할 수 있는 신호 처리를 가능하게 하는 것을 목표로 합니다.

### 기술적 접근

**연구 중인 모델 아키텍처**
1. **순차적(Cascaded) 모델**: 복원과 분류를 분리한 2단계 접근
   - 1단계: BAM/CAE/U-Net을 사용한 복원
   - 2단계: 학습된 분류기를 사용한 분류
   
2. **Multi-Task Learning(MTL) 모델**: End-to-End 공동 최적화
   - 특징 추출을 위한 공유 인코더
   - 복원 및 분류를 위한 이중 디코더
   - 두 작업의 균형을 맞추는 공동 손실 함수

**복원 아키텍처**
- **BAM (Bidirectional Associative Memory)**: 양방향 연결을 가진 Dense 아키텍처
- **CAE (Convolutional Autoencoder)**: 공간적 특징 학습을 위한 합성곱 레이어
- **U-Net**: 세밀한 디테일 보존을 위한 Skip connection

**실험 설계**
- **데이터셋**: CIFAR-10을 150,000장으로 증강
- **노이즈 타입**: Gaussian, Salt & Pepper, Burst 노이즈
- **SNR 레벨**: -30dB, -25dB, -20dB, -15dB, -10dB
- **평가 지표**: 
  - 복원: MSE, MAE, PSNR (dB)
  - 분류: Accuracy, Top-3 Accuracy

### 기술 스택
- **프레임워크**: TensorFlow/Keras, PyTorch
- **모델**: Custom CNN, ResNet, Transformer 기반 아키텍처, BAM, CAE, U-Net
- **도구**: Python, NumPy, Pandas, Jupyter, TensorBoard
- **하드웨어**: NVIDIA RTX 3070 Ti 8GB, Intel i7-12700K

### 팀 구성 및 나의 역할
- **팀 규모**: 개인 연구 프로젝트
- **지도**: 연구 방향에 대한 교수님 지도
- **나의 역할**:
  - 전체 모델 아키텍처 설계 및 구현 (6개 모델)
  - 대규모 데이터 증강 파이프라인 구축 (15만 장)
  - 포괄적인 실험 프레임워크 개발
  - 다양한 조건에서의 통계 분석 및 성능 평가

### 현재 진행 상황
- ✅ 데이터 전처리 및 증강 완료
- ✅ 6개 모델 구현 및 학습 완료 (Sequential BAM/CAE/U-Net, MTL BAM/CAE/U-Net)
- ✅ 노이즈 타입 및 SNR 레벨별 포괄적 평가 프레임워크 구축
- 🔄 최종 비교 분석 및 논문 작성 진행 중

### 예비 결과
- U-Net이 Skip connection으로 인해 우수한 복원 성능 보임
- MTL 모델이 End-to-End 분류 성능에서 우수함
- 노이즈 타입별 성능 차이 큼 (Burst 노이즈가 가장 어려움)
- 높은 SNR 레벨에서 MTL 접근법의 이점이 더 크게 나타남

### 직면한 문제와 해결 방법

**문제 1: 대규모 실험 관리**
- **문제**: 여러 아키텍처(Sequential vs MTL)와 노이즈 조건(3가지 타입 × 5가지 SNR 레벨)에 걸쳐 6개 모델을 관리하고 학습하는 데 상당한 계산 자원과 신중한 실험 추적이 필요함
- **해결**: 각 단계별로 별도의 노트북을 사용한 모듈식 학습 파이프라인 구현, 자동화된 결과 수집 및 분석, 학습 단계 간 체계적인 메모리 관리로 재현성 확보

**문제 2: Ultra-Low SNR을 위한 모델 아키텍처 선택**
- **문제**: 전통적인 방법이 실패하는 극한 노이즈 조건에서 최적의 아키텍처(BAM vs CAE vs U-Net)와 학습 패러다임(Sequential vs MTL) 결정
- **해결**: 포괄적인 문헌 조사 및 모든 조합에 걸친 체계적 비교 수행, 노이즈 타입 및 SNR 레벨별로 성능을 분석하는 커스텀 평가 프레임워크 구현으로 아키텍처별 강점 식별

**문제 3: 현실적인 노이즈 시뮬레이션을 위한 데이터 증강**
- **문제**: 데이터셋 다양성을 유지하면서 Ultra-Low SNR 환경을 정확하게 표현하는 현실적인 노이즈 조건 생성
- **해결**: CIFAR-10을 150,000장으로 확장하는 정교한 데이터 증강 파이프라인 구현, 여러 노이즈 타입(Gaussian, Salt & Pepper, Burst)과 5가지 레벨(-30dB ~ -10dB)에 걸친 정밀한 SNR 제어

**문제 4: Multi-Task 손실 균형**
- **문제**: MTL 모델에서 복원과 분류 손실의 최적 가중치를 찾아 한 작업이 지배하지 않으면서 두 작업 모두 잘 수행되도록 보장
- **해결**: 다양한 손실 가중치 조합 실험 및 공동 최적화 전략 구현, 복원 품질(PSNR)과 분류 정확도 간의 트레이드오프 분석

### 링크
🔗 **프로젝트 저장소**: [github.com/gwon9906/Denoise-and-Classify](https://github.com/gwon9906/Denoise-and-Classify)  
📊 **기술 스택**: TensorFlow, PyTorch, 커스텀 신경망 아키텍처

---

<div style="margin-bottom: 60px;"></div>

## 🔬 <a name="lora-communication"></a>BAM 기반 페이로드 압축을 통한 IoT 통신 효율 개선

**역할**: 학부 연구생 및 팀 리드  
**기간**: 2025년 3월 - 2025년 6월  
**상태**: 완료

### 프로젝트 개요
저자원 임베디드 시스템에 최적화된 경량 페이로드 압축 모델을 설계·구현하여 저전력 고손실 IoT 네트워크의 통신 효율을 개선하는 연구 프로젝트를 주도하고 있습니다.

### 문제 정의
저전력 고손실 네트워크 환경에서 빈번한 재전송으로 인한 통신 비효율 및 배터리 소모 문제가 발생했으며, 특히 비가시권(N-LOS) 환경의 장거리 LoRa 네트워크에서 심각했습니다.

### 기술적 접근

**기술 선택**
- 기존 솔루션(Autoencoder) 분석 및 저자원 환경에서의 부적합성 파악
- 광범위한 논문 스터디와 팀 토론을 통해 저자원 IoT 기기에 최적화된 BAM(Bidirectional Associative Memory) 모델 선정
- Raspberry Pi에서의 이식성과 최소 연산 오버헤드를 위해 TensorFlow 대신 **NumPy로 모델 직접 구현**

**시스템 설계 및 구현**
- 하드웨어 제약(Raspberry Pi)과 통신 프로토콜 한계(LoRa)를 고려한 End-to-End 시스템 아키텍처 설계
- 테스트베드 인프라 구축 및 데이터 분석 파이프라인 개발
- 명확한 역할 분담을 통한 팀 협업: 모델 재구성 및 테스트베드 개발 주도, 팀원은 센서 데이터 수집 및 전처리 담당

**현장 테스트 및 검증**
- 의도적으로 어려운 N-LOS 환경(약 2.6km 거리)에서 엄격한 현장 테스트 수행
- 외부 변수(날씨 조건 등)를 고려하여 테스트 기간을 한 달로 연장
- 데이터 신뢰도 확보를 위한 반복 측정 수행
    
**성능 최적화**
- 모델 정확도에 영향을 미치는 데이터 포맷 문제 식별
- 데이터 전처리 최적화 (예: GPS 데이터 정수부 제거)
- **MSE 80% 이상 개선** (0.0184 → 0.0036) 달성

### 기술 스택
- **언어**: Python, NumPy
- **하드웨어**: Raspberry Pi, LoRa 모듈
- **ML 모델**: Bidirectional Associative Memory (BAM)
- **도구**: Git, Linux

### 팀 구성 및 나의 역할
- **팀 규모**: 4명
- **나의 역할**: 
  - BAM 모델 설계, 구현, 통합 주도
  - 전체 필드 테스트 프로세스 수행 (테스트베드 구축, 데이터 수집, 분석)
  - BAM 관련 모든 기술적 의사결정 및 최적화 담당
- **기여도**: 약 40% (모델 개발 및 필드 검증 리드)

### 직면한 문제와 해결 방법

**문제 1: 필드 테스트 환경 변수**
- **문제**: 장마 등 날씨 조건으로 인한 측정 불일치 및 데이터 신뢰도 문제
- **해결**: 테스트 기간을 2주에서 1개월로 연장하고 반복 측정을 통해 통계적 유의성과 데이터 신뢰도 확보

**문제 2: 모델 성능 최적화**
- **문제**: 부적절한 데이터 포맷으로 인한 초기 모델 정확도 저하 (MSE 0.0184)
- **해결**: 데이터 특성 분석 후 GPS 데이터의 정수부 제거 등 전처리 최적화를 통해 MSE 80% 이상 개선 (0.0184 → 0.0036)

**문제 3: 임베디드 기기의 자원 제약**
- **문제**: Autoencoder가 Raspberry Pi에서 연산 부담이 큼
- **해결**: 문헌 조사 및 팀 토론을 통해 경량 BAM 모델 선정, TensorFlow 대신 NumPy로 직접 구현하여 저자원 하드웨어에서 실시간 동작 보장

### 주요 성과
- ✅ 62.5% 페이로드 압축(32 Bytes → 20 Bytes)을 통한 **PDR(패킷 전달률) 14% 향상**
- ✅ **MSE 0.0036** - 최소 정보 손실
- ✅ 약 2.6km 거리의 실제 N-LOS 환경에서 검증 완료
- ✅ 저자원 Raspberry Pi 플랫폼에 성공적으로 배포

### 향후 개선 방향
동적 데이터(GPS/IMU) 대비 패턴이 명확한 센서 데이터(CPU 온도, 습도 등)에 BAM을 적용하여 더 높은 압축 효율을 달성할 수 있을 것으로 판단됩니다.

### 링크
🔗 **프로젝트 저장소**: [github.com/4xvgal/ChirpChirp](https://github.com/4xvgal/ChirpChirp) - 전체 시스템 구현  
🔗 **BAM 모델**: [github.com/gwon9906/Lightweight-MF-BAM](https://github.com/gwon9906/Lightweight-MF-BAM) - 핵심 압축 모델

---

<div style="margin-bottom: 60px;"></div>

## 📡 <a name="valve-prediction"></a>Encoder-LSTM 기반 산업용 밸브 유량 예측

**역할**: 학부 연구생  
**기간**: 2024년 7월 - 2024년 12월  
**상태**: 완료

### 프로젝트 개요
산업용 밸브 고장 진단을 위한 고정밀 유량 예측 모델을 개발하여 체계적인 데이터 분석과 맞춤형 아키텍처 설계를 통해 **98% 예측 정확도 개선**을 달성했습니다.

### 문제 정의
초기 베이스라인 LSTM 모델의 MAPE(평균 절대 백분율 오차)가 10을 초과하여 실제 산업 현장 적용에 부적합했습니다.

### 기술적 접근

**근본 원인 분석**
- 베이스라인 LSTM 아키텍처의 한계를 체계적으로 진단
- 밸브 개도율 = 0 지점에서 시퀀스가 불연속적이 되어 예측 오류 발생을 식별
- 영점에서 시퀀스 재초기화 구현 → 1차 성능 개선 달성

**아키텍처 혁신**
- Autoencoder 구조에서 영감을 받아 맞춤형 **Encoder-LSTM 아키텍처** 설계
- 시계열 데이터의 핵심 특징 추출에 집중
- 계층적 특징 학습을 통해 일반 LSTM의 한계 극복

**데이터 기반 최적화**
- 데이터 특성 분석: float 값이지만 소수점 정밀도가 낮음을 인식
- 불필요한 정규화 제거 및 정수형 데이터처럼 처리
- 모델 복잡도 감소와 동시에 안정성 향상
- 이상치에 강건한 **Huber 손실 함수** 채택

**실험 방법론**
- 각 최적화 단계를 검증하기 위한 체계적 실험 수행
- 데이터 분할 방법과 모델 성능에 미치는 영향 분석
- 데이터 인사이트 기반 전처리 파이프라인 반복 개선

### 기술 스택
- **프레임워크**: PyTorch
- **모델**: LSTM, Encoder-LSTM (커스텀 아키텍처)
- **손실 함수**: Huber Loss
- **도구**: Python, Pandas, NumPy, Jupyter

### 팀 구성 및 나의 역할
- **팀 규모**: 교수님 지도 하 개인 프로젝트
- **지도**: 방법론 및 결과에 대한 방향성 피드백 및 검증
- **나의 역할**: 
  - 모델 설계 및 구현 전체 소유권
  - 데이터 분석 및 전처리 파이프라인 개발
  - 실험 설계 및 성능 최적화
- **기여도**: 100% (지도교수 조언 하 독립 연구)

### 직면한 문제와 해결 방법

**문제 1: 영점에서의 시퀀스 불연속성**
- **문제**: 밸브 개도율 = 0 지점에서 시퀀스가 불연속적이 되어 예측 오류 발생
- **해결**: 영점에서 시퀀스 재초기화를 구현하여 1차 성능 개선 달성

**문제 2: 베이스라인 모델의 한계**
- **문제**: 일반 LSTM의 정확도가 낮아 (MAPE > 10) 산업 현장 적용 부적합
- **해결**: Autoencoder 구조에서 영감을 받아 커스텀 Encoder-LSTM 아키텍처 설계, 계층적 학습을 통해 시계열 특징을 더 잘 포착

**문제 3: 데이터 특성 불일치**
- **문제**: Float 형식 데이터지만 소수점 정밀도가 낮아 불필요한 모델 복잡도 증가
- **해결**: 데이터 분포 패턴 분석 후 정규화를 제거하고 정수형 데이터처럼 처리하여 모델 복잡도 감소 및 안정성 향상

**문제 4: 이상치 강건성**
- **문제**: MSE 손실 함수가 산업용 센서 데이터의 이상치에 민감함
- **해결**: 이상치에 강건하면서도 그래디언트 안정성을 유지하는 Huber 손실 함수 채택

### 주요 성과
- ✅ **98% 이상 예측 정확도 개선**: MAPE 10 → 0.188
- ✅ 커스텀 Encoder-LSTM 아키텍처 설계 및 구현
- ✅ 강력한 데이터 분석 및 아키텍처 설계 역량 입증
- ✅ 산업 현장 고장 진단의 실용적 적용 가능성 검증

### 핵심 학습 내용
- 모델링 전 데이터 특성 이해의 중요성
- 체계적 실험과 반복적 개선의 가치
- 문제 요구사항에 기반한 맞춤형 아키텍처 설계 능력

### 링크
🔗 **프로젝트 저장소**: Private (산업체 협력)

---

## 💡 추가 경험

### 학부 연구생
**소속**: 동의대학교 컴퓨터공학 연구실  
**기간**: 2022 - 현재

다음 분야의 다양한 연구 프로젝트 참여:
- 신호 처리 및 시계열 예측
- IoT 시스템 및 임베디드 AI
- 저자원 환경을 위한 모델 최적화
- 산업 현장의 실용적 문제 해결

---

## 🎯 기술 역량

### 핵심 강점
1. **End-to-End 시스템 설계**: 하드웨어 통합부터 모델 배포까지 완전한 시스템 구축 경험
2. **모델 최적화**: 모델 압축(페이로드 62.5% 감소) 및 성능 개선(오차율 98% 감소) 검증된 능력
3. **데이터 분석**: 데이터 패턴 식별 및 적절한 전처리 전략 설계에 대한 강력한 기술
4. **문제 해결**: 문제 진단 및 효과적인 솔루션 구현에 대한 체계적 접근법

### 도메인 전문성
- 시계열 예측 및 분석
- IoT 통신 프로토콜 (LoRa)
- 저자원 기기에서의 임베디드 AI
- 산업용 AI 응용

---

<div style="text-align: center; margin-top: 40px;">
  <a href="/index_ko" style="text-decoration: none; padding: 10px 20px; background-color: #0366d6; color: white; border-radius: 5px;">← 홈으로 돌아가기</a>
</div>

